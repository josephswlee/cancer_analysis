---
title: "Cancer Analysis"
author: "Joseph Lee (sl5nj), Umar Abushaban (uba6z), William Cull (wjc5rt)"
date: "2/1/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
#Load libraries
#library(e1071)
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)
library(NbClust)
library(randomForest)
library(rio)
library(plyr)
library(rpart)
library(pROC)
library(rpart.plot)
library(rattle)
library(mlbench)
library(MLmetrics)
library(ROCR)
library(mltools)
library(data.table)
library(ggplot2)
library(class)
```

```{r}
setwd("/Users/sangwoolee/Dev/DS4002/4002_handsOn/project1/cancer_analysis")
```


Reading in the Data
```{r}
cancer = read.csv("./cancer.csv")
```

Cleaning up the data
```{r}
#convert variable names
cancer$diagnosis[cancer$diagnosis == "M"] <- 1
cancer$diagnosis[cancer$diagnosis == "B"] <- 0

#Remove the last "x" column
cancer = cancer[, -c(33)]
str(cancer)
#Convert the diagnosis variable to a factor
#complete.cases(cancer)
cancer$id = as.factor(cancer$id)
cancer$diagnosis = as.factor(cancer$diagnosis)
#View(cancer)
table(cancer$diagnosis)

#remove id for test
cancer = cancer[, -c(1)]
```

```{r}
sample_rows = 1:nrow(cancer)
#sample_rows

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(cancer)[1]*.10, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

# Partition the data between training and test sets using the row numbers the
# sample() function selected.
cancer_train = cancer[-test_rows,]
cancer_test = cancer[test_rows,]

dim(cancer)
```

```{r}
###### for tune

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(cancer_test)[1]*.50, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

tune = cancer_test[-test_rows,]
test = cancer_test[test_rows,]

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(tune)[1]*.50, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

x_tune = tune[-test_rows,]
y_tune = tune[test_rows,]
```

```{r}
mytry_tune <- function(x){
  xx <- dim(x)[2]-1
  sqrt(xx)
}
mytry_tune(cancer) #5.477226
```

Random Forest
```{r}
set.seed(2023)  
cancer_RF = randomForest((diagnosis)~.,      
                            cancer_train,   
                            #y = NULL,        
                            #subset = NULL,    
                            #xtest = NULL,     
                            #ytest = NULL,     
                            ntree = 500,      
                            mtry = 5,      
                            replace = TRUE,   
                            #classwt = NULL,   
                            #strata = NULL,   
                            sampsize = 100,    
                            nodesize = 5,    
                            #maxnodes = NULL,  
                            importance = TRUE,  
                            #localImp = FALSE, 
                            proximity = FALSE,  
                            norm.votes = TRUE, 
                            do.trace = TRUE,   
                            keep.forest = TRUE, 
                            keep.inbag = TRUE)   
```

```{r}
cancer_RF
cancer_RF$call
cancer_RF$confusion
```

```{r}
cancer_RF_acc = sum(cancer_RF$confusion[row(cancer_RF$confusion) == 
                                                col(cancer_RF$confusion)]) / 
  sum(cancer_RF$confusion)

cancer_RF_acc
```

```{r}
# The accuracy of this model is 0.8404

#### Random forest output ####

#View(as.data.frame(cancer_RF$votes))

# The "inbag" argument shows you which data point is included in which trees.
str(as.data.frame(cancer_RF$inbag))
```

```{r}
#View(as.data.frame(cancer_RF$inbag))

inbag <- as.data.frame(cancer_RF$inbag)

sum(inbag[,500])
```

```{r}
dim(cancer_RF$inbag)
```

```{r}
err.rate <- as.data.frame(cancer_RF$err.rate)
err.rate
```

```{r}
#### Visualize random forest results ####

# Let's visualize the results of the random forest.
# Let's start by looking at how the error rate changes as we add more trees.
cancer_RF_error = data.frame(1:nrow(cancer_RF$err.rate),
                                cancer_RF$err.rate)
#View(cancer_RF_error)

colnames(cancer_RF_error) = c("Number of Trees", "Out of the Box",
                                 "Benign", "Malignant")

# Add another variable that measures the difference between the error rates, in
# some situations we would want to minimize this but need to use caution because
# it could be that the differences are small but that both errors are really high,
# just another point to track. 

cancer_RF_error$Diff <- cancer_RF_error$`Benign`-cancer_RF_error$`Malignant`

#View(cancer_RF_error)

#rm(fig)
fig <- plot_ly(x=cancer_RF_error$`Number of Trees`, y=cancer_RF_error$Diff,name="Diff", type = 'scatter', mode = 'lines')
fig <- fig %>% add_trace(y=cancer_RF_error$`Out of the Box`, name="OOB_Er")
fig <- fig %>% add_trace(y=cancer_RF_error$`Malignant`, name="Malignant")
fig <- fig %>% add_trace(y=cancer_RF_error$`Benign`, name="Benign")

fig
```

More random forest model

Modified ntree 500 -> 1000 and samplesize 100 -> 200
```{r}
set.seed(2023)  
cancer_RF2 = randomForest((diagnosis)~.,        
                            cancer_train, 
                            #y = NULL,      
                            #subset = NULL,   
                            #xtest = NULL,      
                            #ytest = NULL,   
                            ntree = 800,   
                            mtry = 5,     
                            replace = TRUE, 
                            #classwt = NULL, 
                            sampsize = 200,      
                            nodesize = 20,       
                            #maxnodes = NULL,  
                            importance = TRUE,   
                            #localImp = FALSE,  
                            proximity = FALSE, 
                            norm.votes = TRUE,  
                            do.trace = TRUE,    
                            keep.forest = TRUE, 
                            keep.inbag = TRUE)    
```

```{r}
cancer_RF2
cancer_RF2$call
cancer_RF2$confusion
```

```{r}
cancer_RF_acc2 = sum(cancer_RF2$confusion[row(cancer_RF2$confusion) == 
                                                col(cancer_RF2$confusion)]) / 
  sum(cancer_RF2$confusion)

cancer_RF_acc2
```

```{r}
# The accuracy of this model is 0.8404

#### Random forest output ####

#View(as.data.frame(cancer_RF$votes))

# The "inbag" argument shows you which data point is included in which trees.
str(as.data.frame(cancer_RF2$inbag))
```

```{r}
#View(as.data.frame(cancer_RF2$inbag))

inbag <- as.data.frame(cancer_RF2$inbag)

sum(inbag[,500])
```

```{r}
dim(cancer_RF2$inbag)
```

```{r}
err.rate2 <- as.data.frame(cancer_RF2$err.rate)
err.rate2
```

```{r}
#### Visualize random forest results ####

# Let's visualize the results of the random forest.
# Let's start by looking at how the error rate changes as we add more trees.
cancer_RF_error2 = data.frame(1:nrow(cancer_RF2$err.rate),
                                cancer_RF2$err.rate)
#View(cancer_RF_error2)

colnames(cancer_RF_error2) = c("Number of Trees", "Out of the Box",
                                 "Benign", "Malignant")

# Add another variable that measures the difference between the error rates, in
# some situations we would want to minimize this but need to use caution because
# it could be that the differences are small but that both errors are really high,
# just another point to track. 

cancer_RF_error2$Diff <- cancer_RF_error2$`Benign`-cancer_RF_error2$`Malignant`

#View(cancer_RF_error)

#rm(fig)
fig2 <- plot_ly(x=cancer_RF_error2$`Number of Trees`, y=cancer_RF_error2$Diff,name="Diff", type = 'scatter', mode = 'lines')
fig2 <- fig2 %>% add_trace(y=cancer_RF_error2$`Out of the Box`, name="OOB_Er")
fig2 <- fig2 %>% add_trace(y=cancer_RF_error2$`Malignant`, name="Malignant")
fig2 <- fig2 %>% add_trace(y=cancer_RF_error2$`Benign`, name="Benign")

fig2
```

Variable Importance
```{r}
varImpPlot(cancer_RF2, 
           sort = TRUE,
           n.var = 10,        
           main = "Important Factors for diagnosis",
           #cex = 2,           
           bg = "white",       
           color = "blue",     
           lcolor = "orange")  
```

Evaluating Model
```{r}
cancer_predict = predict(cancer_RF2,    
                            cancer_test,      
                            type = "response",   
                            predict.all = TRUE, 
                            proximity = FALSE)  
#cancer_predict
```

```{r}
cancer_test_pred = data.frame(cancer_test, 
                                 Prediction = cancer_predict$aggregate)



# Create the confusion matrix.
cancer_test_matrix_RF = table(cancer_test_pred$diagnosis, 
                            cancer_test_pred$Prediction)

cancer_test_matrix_RF
```

```{r}
# Calculate the misclassification or the error rate.
cancer_test_error_rate_RF = sum(cancer_test_matrix_RF[row(cancer_test_matrix_RF) != 
                                                    col(cancer_test_matrix_RF)]) / 
  sum(cancer_test_matrix_RF)

cancer_test_error_rate_RF
```


```{r}
#   0  1
#0 34  0
#1  1 21

# False Positive Rate
1/(1+34)
```

```{r}
confusionMatrix(cancer_test_pred$Prediction,cancer_test_pred$diagnosis,positive = "1", 
                dnn=c("Prediction", "Actual"), mode = "everything")
```


Graphing radius by diagnosis
```{r}
ggplot(cancer, aes(x=diagnosis, y=radius_mean,color = diagnosis)) +
  geom_point(alpha = 1/20) +
  geom_point(size=0.1) +
  labs(title = "Diagnosis by Radius", x="Diagnosis", y="Radius",) +
  scale_color_manual(labels = c("benign", "malignant"), values = c("green", "red")) +
  scale_x_discrete(labels=c("1" = "malignant", "0" = "benign"))
```
